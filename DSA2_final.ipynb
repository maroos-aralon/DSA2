{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from difflib import SequenceMatcher, ndiff\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from jellyfish import levenshtein_distance, damerau_levenshtein_distance, hamming_distance, jaro_similarity, jaro_winkler_similarity\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "# from time import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T13:49:03.122854900Z",
     "start_time": "2024-04-17T13:49:03.096428700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:18:47.223510700Z",
     "start_time": "2024-04-17T14:18:44.252822600Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "df_train = pd.read_csv('Contents/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('Contents/test.csv', encoding=\"ISO-8859-1\")\n",
    "df_attr = pd.read_csv('Contents/attributes.csv')\n",
    "df_pro_desc = pd.read_csv('Contents/product_descriptions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Select random subset of training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "rng=np.random.RandomState(12)\n",
    "\n",
    "train_indices = rng.choice(74067, replace=False, size=12000)\n",
    "df_train = df_train.iloc[train_indices]\n",
    "\n",
    "test_indices = rng.choice(166693, replace=False, size=9000)\n",
    "df_test = df_test.iloc[test_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T12:05:24.267636700Z",
     "start_time": "2024-04-17T12:05:24.217643900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "outputs": [],
   "source": [
    "def str_stemmer(s):\n",
    "\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "def levenshtein(input_string, reference_string):\n",
    "    # if reference_string == 'nan':\n",
    "    #     score = np.nan\n",
    "    # else:\n",
    "    score = 1-levenshtein_distance(input_string, reference_string)\n",
    "    return score\n",
    "\n",
    "def check_for_numeral(input_string):\n",
    "    if any(char.isdigit() for char in input_string):\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def check_for_unit(input_string):\n",
    "    score = 0\n",
    "    units = ['lb', 'in', 'cu', 'ft', 'min', 'oz']\n",
    "    for unit in units:\n",
    "        if unit in input_string:\n",
    "            score += 1\n",
    "    return score\n",
    "\n",
    "def average_word_length(input_string):\n",
    "    letter_sentence = re.findall(r'\\w+', input_string)\n",
    "\n",
    "    # Calculate the total number of characters and the number of words\n",
    "    total_chars = len(''.join(letter_sentence))\n",
    "    num_words = len(letter_sentence)\n",
    "\n",
    "    # Compute the average word length\n",
    "    avg_word_length = total_chars / float(num_words)\n",
    "\n",
    "    return avg_word_length\n",
    "\n",
    "def extract_numeric_before_string(input_string, specified_string):\n",
    "    pattern = rf\"(\\d+)\\s*{re.escape(specified_string)}\"\n",
    "\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    if match:\n",
    "        numeric_value = float(match.group(1))\n",
    "        return numeric_value\n",
    "    else:\n",
    "        return 'nan'\n",
    "\n",
    "def matched_numeric(input_string, measurements):\n",
    "    score = 0\n",
    "    units = ['in','in','in','lb']\n",
    "    for u_id, unit in enumerate(units):\n",
    "        if measurements[u_id] == 'nan':\n",
    "            continue\n",
    "        if unit in input_string:\n",
    "                try:\n",
    "                    value = float(extract_numeric_before_string(input_string, unit))\n",
    "                    if value == 'nan':\n",
    "                        pass\n",
    "                    lower_limit = float(measurements[u_id]) * 0.9\n",
    "                    upper_limit = float(measurements[u_id]) * 1.1\n",
    "                    if lower_limit <= value <= upper_limit:\n",
    "                        score += 1\n",
    "                except ValueError:\n",
    "                    pass\n",
    "#            if str(measurements[u_id]) in input_string:\n",
    "#                score +=1\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:33:07.862070700Z",
     "start_time": "2024-04-17T14:33:07.850828100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "outputs": [],
   "source": [
    "num_train = df_train.shape[0]\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "# attributes\n",
    "color_attribute = df_attr.loc[df_attr['name']=='Color Family'].drop(['name'], axis=1).rename(columns={'value':'color_family'})\n",
    "brand_name = df_attr.loc[df_attr['name']=='MFG Brand Name'].drop(['name'], axis=1).rename(columns={'value':'brand_name'})\n",
    "\n",
    "width = df_attr.loc[df_attr['name']==\"Product Width (in.)\"].drop(['name'], axis=1).rename(columns={'value':'width'})\n",
    "height = df_attr.loc[df_attr['name']==\"Product Height (in.)\"].drop(['name'], axis=1).rename(columns={'value':'height'})\n",
    "depth = df_attr.loc[df_attr['name']==\"Product Depth (in.)\"].drop(['name'], axis=1).rename(columns={'value':'depth'})\n",
    "weight = df_attr.loc[df_attr['name']==\"Product Weight (lb.)\"].drop(['name'], axis=1).rename(columns={'value':'weight'})\n",
    "\n",
    "df_all = pd.merge(df_all, color_attribute, how=\"left\", on=\"product_uid\")\n",
    "df_all = pd.merge(df_all, brand_name, how=\"left\", on=\"product_uid\")\n",
    "df_all = pd.merge(df_all, width, how=\"left\", on=\"product_uid\")\n",
    "df_all = pd.merge(df_all, height, how=\"left\", on=\"product_uid\")\n",
    "df_all = pd.merge(df_all, depth, how=\"left\", on=\"product_uid\")\n",
    "df_all = pd.merge(df_all, weight, how=\"left\", on=\"product_uid\")\n",
    "\n",
    "# stemming\n",
    "df_all['color_family'] = df_all['color_family'].map(lambda x:str_stemmer(str(x)))\n",
    "df_all['brand_name'] = df_all['brand_name'].map(lambda x:str_stemmer(str(x)))\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "# quantitative data\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "# df_all['word_length'] = df_all.apply(lambda x: average_word_length(x['search_term']), axis=1)\n",
    "\n",
    "# product info\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n",
    "df_all['measurements'] = df_all.apply(lambda row: [row['width'], row['height'], row['depth'], row['weight']], axis=1)\n",
    "\n",
    "# similarity data\n",
    "df_all['title_similarity'] = df_all.apply(lambda x: str_common_word(x['search_term'], x['product_title']), axis=1)\n",
    "df_all['description_similarity'] = df_all.apply(lambda x: str_common_word(x['search_term'], x['product_description']), axis=1)\n",
    "df_all['color_similarity'] = df_all.apply(lambda x: levenshtein(x['search_term'], x['color_family']), axis=1)\n",
    "df_all['brand_in_title'] = df_all.apply(lambda x: str_common_word(x['search_term'], x['brand_name']), axis=1)\n",
    "\n",
    "# numerals + units\n",
    "df_all['numeral_in_search'] = df_all.apply(lambda x: check_for_numeral(x['search_term']), axis=1)\n",
    "df_all['unit_in_search'] = df_all.apply(lambda x: check_for_unit(x['search_term']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:26:21.502595600Z",
     "start_time": "2024-04-17T14:18:50.907436200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "outputs": [],
   "source": [
    "# df_all['matched_measurement'] = df_all.apply(lambda x: matched_numeric(x['search_term'], x['measurements']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:33:15.093171200Z",
     "start_time": "2024-04-17T14:33:11.862365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "df_save = df_all"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info','color_family', 'brand_name', 'height','width','depth', 'weight', 'measurements'],axis=1)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:33:18.789628500Z",
     "start_time": "2024-04-17T14:33:18.771144200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('df_all_stemmed.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','relevance'],axis=1), df_train['relevance'], test_size=0.20, random_state=42)\n",
    "id_test = X_test['product_uid']\n",
    "X_train = X_train.drop(['product_uid'], axis=1)\n",
    "X_test = X_test.drop(['product_uid'], axis=1)\n",
    "\n",
    "# id_test = X_test[:, 0]\n",
    "# X_train = X_train[:,1:]\n",
    "# X_test = X_test[:,1:]\n",
    "\n",
    "#X_train = np.where(np.isnan(X_train), 0, X_train)\n",
    "#X_test = np.where(np.isnan(X_test), 0, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:37:02.568021500Z",
     "start_time": "2024-04-17T14:37:02.519279Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Base Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "# clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "#\n",
    "# pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('week7_1.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T12:50:43.257389Z",
     "start_time": "2024-04-17T12:50:43.255879200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chosen Model (Decision Tree)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 3, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 5]\n",
    "}\n",
    "# Set up the grid search\n",
    "grid_cv = GridSearchCV(model, hyperparameter_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Fit it to the data and find the best hyperparameters\n",
    "grid_fit = grid_cv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_fit.predict(X_test)\n",
    "\n",
    "coefs = grid_fit.best_estimator_.feature_importances_\n",
    "names = grid_fit.best_estimator_.feature_names_in_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:37:18.436733600Z",
     "start_time": "2024-04-17T14:37:05.678837600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "outputs": [
    {
     "data": {
      "text/plain": "   title_similarity  len_of_query  color_similarity  description_similarity  \\\n0          0.527103      0.276926          0.099491                0.078097   \n\n   brand_in_title  matched_measurement  \n0        0.014961             0.003423  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_similarity</th>\n      <th>len_of_query</th>\n      <th>color_similarity</th>\n      <th>description_similarity</th>\n      <th>brand_in_title</th>\n      <th>matched_measurement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.527103</td>\n      <td>0.276926</td>\n      <td>0.099491</td>\n      <td>0.078097</td>\n      <td>0.014961</td>\n      <td>0.003423</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_weight = pd.DataFrame([coefs], columns=names)\n",
    "feature_weight = feature_weight.T.sort_values(by=feature_weight.index[0], ascending=False).T\n",
    "display(feature_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:37:19.015879400Z",
     "start_time": "2024-04-17T14:37:18.991690100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4810364294165028\n"
     ]
    }
   ],
   "source": [
    "def root_mean_squared_error(y_test, y_pred):\n",
    "\trmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\treturn rmse\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:37:25.132321200Z",
     "start_time": "2024-04-17T14:37:25.113001400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scores:\n",
    "\n",
    "Decision Tree\n",
    "- subset, with stem, color, Jaro sim: 0.5408981607863628\n",
    "- subset, with stem, color, Jaro-wink sim: 0.5411629191097017\n",
    "- subset, with stem, color, damereau-lev sim: 0.5379426945018496\n",
    "- subset, with stem, color, hamming dist: 0.5380565876357295\n",
    "- subset, with stem, color, levenshtein dist: 0.5372710196551093\n",
    "- subset, with stem, color, brand, levenshtein dist (only for color): 0.5297623475074125\n",
    "- subset, with stem, color, brand, levenshtein dist (color and brand): 0.5227914391340877\n",
    "- subset, with stem, color, brand, levenshtein dist (all features): 0.5320546275888145\n",
    "- subset, with stem, color, brand, levenshtein dist (except title): 0.5126117989966398\n",
    "- subset, with stem, color, brand, check_for_numeral levenshtein dist (except title): 0.5088087146629251\n",
    "- subset, with stem, brand, check_for_numeral levenshtein dist (except title): 0.5106889448309334\n",
    "- subset, with stem, color, brand, check_for_numeral, no levenshtein: 0.5016388501818894\n",
    "- subset, with stem, color, brand, check_for_numeral levenshtein dist (except title), no NaN filtering: 0.5030290160948324\n",
    "\n",
    "\n",
    "\n",
    "- full set, with stem, color, levenshtein dist: 0.5272314796949449\n",
    "- full set, with stem, color, levenshtein dist (only for color): 0.5240342623526805\n",
    "- full set, with stem, color, brand, check_for_numeral levenshtein dist (except title): 0.5101046665678989\n",
    "- full set, with stem, color, brand, check_for_numeral levenshtein dist (except title): 0.49271495137454396\n",
    "- full set, with stem, color, brand, check_for_numeral levenshtein dist (except title + description), no NaN filtering: 0.4817504691987292\n",
    "- full set, with stem, brand, check_for_numeral levenshtein dist (except title + description), no NaN filtering: 0.4828603848093095\n",
    "- fully stemmed set without additions: 0.4860708012587651\n",
    "- full set, with stem, color, brand, check_for_numeral, check for unit, levenshtein dist (except title + description), no NaN filtering: 0.4810337659750626\n",
    "- full set, with stem, color, brand, check_for_numeral, check for unit, average_word, levenshtein dist (except title + description), no NaN filtering: 0.4812782783434426\n",
    "- full set, with stem, color, brand, check_for_numeral, check for unit, average_word, levenshtein dist (except title + description, brand), no NaN filtering: 0.48017502966180736\n",
    "\n",
    "\n",
    "- original model with a 80/20 split: 0.4848881549747362\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
